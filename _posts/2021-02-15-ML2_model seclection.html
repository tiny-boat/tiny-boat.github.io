---
layout: post
title:  "机器学习(2):模型选择"
date:   2021-02-15 23:33:00
categories: Computer_Science Statistics Machine_Learning
excerpt: "模型选择是整个建模过程中一个十分重要的环节。所谓模型选择，简单来说就是从多个可能模型中选择出一个作为最终的建模结果。如果使用机器学习中的一些术语，我们可以说模型选择是从多种学习算法或拥有不同参数配置的同一学习算法中选择出其中某个学习算法或某种参数配置。笔者本科毕业论文探讨的就是一种重要的模型选择方法（k 折交叉验证）的细节问题，以下内容是笔者论文的开头部分"
permalink: /machine_learning/2/model_selection/
---

<div class="post-style">

<blockquote>参考文献：① 周志华. 机器学习[M]. 北京:清华大学出版社. 2016.01. ② 李航. 统计学习方法[M]. 北京:清华大学出版社. 2012.03.
</blockquote>

<p>模型选择是整个建模过程中一个十分重要的环节。所谓模型选择，简单来说就是从多个可能模型中选择出一个作为最终的建模结果。如果使用机器学习中的一些术语，我们可以说模型选择是从多种学习算法或拥有不同参数配置的同一学习算法中选择出其中某个学习算法或某种参数配置。笔者本科毕业论文探讨的就是一种重要的模型选择方法（k 折交叉验证）的细节问题，以下内容是笔者论文的开头部分：</p>

<blockquote>千百年来，人们可能做过许许多多的美梦，期待着科学的发展能够帮助人们不断逼近世间万物的真相。今天，随着互联网尤其是移动互联网的发展，信息爆炸式增长的时代已然来临，各种各样庞大的数据集正如潮水一般向我们涌来。而统计学，作为一门以数据为中心的学科，正在义不容辞地承担起这个“帮助人们逼近世间万物真相”的重任。在统计学家的世界里，有一件东西很重要，那就是建立模型（简称建模）。建模之于统计学，就像筷子之于中国人的饮食、刀叉之于英国人的饮食一样，不可或缺。统计学家正是用基于数据构建的模型来试图逼近世间万物真相的。</blockquote>

<blockquote>在与 Norman R. Draper 合著的《Empirical Model-Building and Response Surfaces》一书中，英国著名统计学家，Box-Jenkins 模型（即 ARIMA 模型）及 Box-Cox 变换的提出者 George Edward Pelham Box 这样写道：虽然从本质上来说，所有的模型都是错的，但它们中的一些是有用的（原文：essentially, all models are wrong, but some are useful）。这一发人深省的话语告诉人们：统计推断所用模型是基于不完全信息确定的，而信息的不完全使得错误的发生在所难免，然而这并不代表统计建模是毫无意义的骗人把戏，相反，只要我们能将错误控制在一定范围之内，那么这个模型对于实际应用而言就是有用的。</blockquote>

<blockquote>事实上，信息的不完全正是统计推断赖以存在的前提与基础。试想，如果一个人拥有了未卜先知的能力，他能够获得关于未来的所有信息，那么当荧屏上出现诸如天气预报、股价预测等的画面时，他会有怎样的反应呢？笔者觉得，这位天神下凡般的人物可能会在一旁暗自嘲笑道：这帮愚蠢的人类，真是朽木不可雕也。虽然信息的不完全使得统计推断有了它存在的意义与价值，但与此同时，它也使得不同的人甚至同一个人在面对相同问题时，可能建立多种不同的模型。于是，一个现实而重要的问题就摆在了人们的面前，它就是模型的选择。</blockquote>

<blockquote>人们似乎期待着模型选择能够实现这样的功能，即在所有可能模型中，选择出与真实情况最为接近，或换句话说，选择出误差或损失最小的模型。然而遗憾的是，这几乎是不可能的。问题在于：我们无法穷尽所有可能模型，我们并不知道所谓真实情况，我们也没有关于误差或损失的唯一衡量标准。于是，模型选择这样的问题，就像模型建立这样的问题一样，成了一个仁者见仁、智者见智的问题。借用 George Edward Pelham Box 的话说就是：从本质而言，所有的模型选择方法也是错的，但它们中的一些是有用的。</blockquote>

<p class="post-text-noindent">接下来，我们将依次介绍模型选择中的一些基本术语和模型选择的常用方法。</p>

<h1>2.1 基本术语</h1>

<p>我们将模型/学习器的预测输出与样本的真实输出之间的差异称之为<strong>误差</strong> (error)，将模型/学习器在训练集、测试集、新样本上的误差分别称为<strong>训练误差</strong>/<strong>经验误差</strong> (training error / testing error)、<strong>测试误差</strong> (testing error) 和<strong>泛化误差</strong> (generalization error). 对分类问题，我们将分类错误的样本数占样本总数的比例称之为<strong>错误率</strong> (error rate)，将“1-错误率”称之为<strong>精度</strong> (accuracy).</p>

<p>对给定的某个数据集，当模型/学习器将训练样本自身的一些特点当作所有潜在样本都具有的一般性质时，我们将称该模型/学习器<strong>过拟合</strong> (overfitting) 或过配。如果学习器对训练样本的一般性质尚未学好，我们称该模型/学习器<strong>欠拟合</strong> (underfitting) 或欠配。</p>

<blockquote>过拟合是一个无法彻底避免的现象，因为机器学习面临的问题是 NP 难甚至更难的，而有效的学习算法必然是在多项式时间内运行完成的，若可彻底避免过拟合，则通过经验误差最小化就能获得最优解，而这意味着我们构造性地证明了 P=NP，这种自相矛盾告诉我们过拟合无法彻底避免，因此机器学习的各类算法都必然带有一些针对过拟合的措施。欠拟合则比较容易克服，例如在决策树学习中扩展分支，在神经网络学习中增加训练轮数等。</blockquote>

<blockquote>关于 NP 难及其所涉及的计算理论，笔者将在学习完计算机科学导论中有关计算理论的部分后于专题文章中加以阐述，这里如果读者不是很懂这些概念也没关系，暂时跳过吧。</blockquote>

<p>我们将对算法参数进行设定的过程称之为<strong>调参</strong> (parameter tuning)，在很多强大的学习算法中有不少参数需要设定，这将导致极大的调参工程量，以至于在不少应用任务中，参数调得好不好往往对最终模型性能有关键性影响。此外，有一点值得注意，那就是：学习算法的很多参数在实数范围内取值，因此，对每种参数配置都训练出模型来是不可行的。现实中常用的做法是对每个参数选定一个范围和变化步长。</p>

<h1>2.2 常用方法</h1>

<p>本节，我们将依次阐述有监督学习模型选择常用方法和无监督学习模型选择常用方法。</p>

<h2>2.2.1 有监督学习</h2>

<p>本小节，笔者将试着从一个统一的框架出发，对有监督学习中常见的模型选择方法做一个系统性的阐述。总的来说，我们期待选择这样一个模型，它对未知数据的预测效果最好。然而，我们没有办法准确计算一个模型对未知数据的预测效果，我们只能通过某些方法去估计一个模型对未知数据的预测效果，与此同时，究竟什么叫预测效果好，并没有一个统一的衡量标准，它取决于实际问题、实际需求、看待问题的角度等等。于是，对模型实际预测效果进行估计的不同方法与衡量模型预测效果的不同标准的组合，构成了多种多样的模型选择方法。</p>

<p>笔者将对模型实际预测效果进行估计的方法概括为如下三大类：</p>

<ul>
	<li>利用模型在样本内的预测效果估计模型实际预测效果：如样本内预测均方误差、样本内预测平均绝对误差、样本内分类错误率等；</li>
	<li>利用模型在样本内的预测效果与模型复杂度的加权和估计模型实际预测效果：如 AIC、BIC 等；</li>
	<li>利用模型在样本外的预测效果估计模型实际预测效果：如交叉验证、包外估计等。</li>
</ul>

<p class="post-text-noindent">而常见的衡量模型预测效果的标准有：</p>

<ul>
	<li>经验风险（empirical risk）：损失函数的平均</li>
	$$R_{emp} = \frac{1}{n} \sum_{i=1}^n L \left(y_i,f \left(\boldsymbol{x}_i \right ) \right )$$
</ul>

<blockquote>
常见损失函数有：0-1 损失函数、平方损失函数、绝对损失函数、对数似然损失函数/交叉墒损失函数。0-1 损失函数对应的经验风险即为分类错误率，通常用于分类问题；平方损失函数对应的经验风险即为均方误差，通常用于回归问题；绝对损失函数对应的经验风险即为平均绝对误差，通常用于回归问题；对数似然损失函数与交叉墒损失函数是等价的，既适用于分类问题也适用于回归问题。
</blockquote>

<ul>
	<li>仅适用于二分类问题的查准率/精确率（precision）、查全率/召回率（recall）、平衡点（break-even point, BEP）、$F_\beta$ 度量</li>
	$$P = \frac{TP}{TP + FP}$$
	$$R = \frac{TP}{TP + FN}$$
	BEP：P-R 图中 P=R 时 P 或 R 的取值
	$$F_\beta = \frac{\left(1+\beta^2 \right )PR}{\left(\beta^2P \right )+R}$$
</ul>

<blockquote>查准率和查全率这一术语来自于信息检索领域，所谓查准率指的是查到的信息中用户真正感兴趣的占多少，所谓查全率指的是用户感兴趣的所有内容中真正被查出来的占多少。不同业务场景下对查准率和查全率的重视程度是不一样的，以笔者目前接触的公司负面舆情预警工作而言，凡是互联网上有的关于公司的负面舆情都应尽量获得，以最大程度规避负面舆情对公司发展造成的不利影响。此时，查全率的重要性要高于查准率，当然这并不是说查准率不重要，只不过重要性要比查全率低。但当公司想要将这一工作提升到对外服务的高度，查准率的重要性会随之提升，毕竟当使用者面对一个检索出的信息中存在大量非负面舆情的系统时，使用体验会很差。P-R 图是二分类学习器在不同分类阈值情况下 (R, P) 点的连线图，如果一个学习器的 P-R 图完全包围另一个学习器，则在综合考虑查准率和查全率的视角下，认为该学习器性能更优。平衡点或 $F_\beta$ 度量也是综合考虑查准率和查全率的例子，当 $\beta > 1$ 时，查全率有更大影响，当 $beta < 1$ 时，查准率有更大影响。特别地，$F_1$ 度量是查准率和查全率的调和平均。</blockquote>

<ul>
	<li>仅适用于二分类问题的真正例率（true positive rate, TPR）、假正例率（false positive rate, FPR）、约登指数（Youden index, Youden）（ROC 图与围成面积 AUC）</li>
	$$TPR = \frac{TP}{TP + FN}$$
	$$FPR = \frac{FP}{TN + FP}$$
	$$Youden = TPR - FPR$$
</ul>

<blockquote>TPR 代表正样本被正确分类的几率，1 - FPR 代表负样本被正确分类的几率。ROC 图是二分类学习器在不同分类阈值情况下（FPR, TPR）点的连线图，如果一个学习器的 ROC 图完全包围另一个学习器，则在综合考虑真正例率和假正例率的视角下，认为该学习器性能更优。Youden 指数也是综合考虑真正例率和假正例率的例子，它可视作 TPR 和 1 - FPR 的等权平均。类似 $F_\beta$ 度量，只需对 TPR 和 1 - FPR 赋予不同的权重，我们便可得到 $Youden_\beta$ 度量</blockquote>

<blockquote>在非均等代价下，应使用代价曲线代替 ROC 曲线，ROC 曲线上每一点（TPR, FPR）对应一条从（0, TPR）到（1, 1 - TPR）的线段，所有线段的下界则构成代价曲线。代价曲线所围面积为期望总体代价。</blockquote>

<ul>
	<li>适用于多分类问题的宏查准率/微查准率（macro-P / micro-P）、宏查全率/微查全率（macro-R / micro-R）、宏平衡点/微平衡点（macro-BEP / micro-BEP）、宏 $F_\beta$ 度量/微 $F_\beta$ 度量（macro-$F_\beta$ / micro-$F_\beta$）、宏真正例率/微真正例率（macro-TPR / micro-TPR）、宏假正例率/微假正例率（macro-FPR / micro-FPR）、宏约登指数/微约登指数（macro-Youden / micro-Youden）</li>
	$$macro-P = \frac{1}{n} \sum_{i=1}^{n}P_i,\ P_i = \frac{TP_{i}}{TP_{i} + FP_{i}}$$
	$$micro-P = \frac{\bar{TP}}{\bar{TP} + \bar{FP}}, \bar{TP} = \frac{1}{n} \sum_{i=1}^{n}TP_i, \bar{FP} = \frac{1}{n} \sum_{i=1}^{n}FP_i$$
	其余类似可得
</ul>

<blockquote>macro-P / micro-P 等指标是二分类问题向多分类问题的自然推广</blockquote>

<h2>2.2.2 无监督学习</h2>

<p>本小节，我们介绍无监督学习中的模型选择方法。聚类和降维是无监督学习最主要的两个例子，聚类模型有多种多样的评价方法，而降维模型则通常根据降维后有监督学习的效果进行选择。这里我只阐述聚类的评价指标。</p>

<p>聚类的评价指标分为内部指标和外部指标，常用的内部指标有：</p>

<ul>
    <li>DB 指数（Davies-Bouldin index, DBI）：$$DBI = \frac{1}{k} \sum_{i=1}{k} \max_{j\ne i} \left(\frac({\rm avg}(C_i) + {\rm avg}(C_j)){d_{\rm cen}(C_i, C_j)} /\right)$$</li>
    其中 ${\rm avg}(C_i)$ 代表簇 $C_i$ 内所有样本的平均距离，${\rm avg}(C_j)$ 代表簇 $C_j$ 内所有样本的平均距离，$d_{\rm cen}(C_i, C_j)$ 代表簇 $C_i$ 中心点和簇 $C_j$ 中心点距离，中心点定义为簇内样本点的平均。
    <li>Dunn 指数（Dunn index, DI）：$$DI = \min_{1\leq i \leq k}\left\{\min_{j\ne i}\left(\frac{d_{\min}(C_i, C_j)}{\max_{1\leq l \leq k}{\rm diam}(C_l)} \right) \right\}$$</li>
    其中 $d_{\min}(C_i, C_j)$ 代表簇 $C_i$ 内样本点和簇 $C_j$ 内样本点之间的最短距离，${\rm diam}(C_l)$ 代表簇 $C_l$ 内样本点最大距离。
</ul>

<blockquote>我们通常认为 DBI 指数越小或 DI 指数越大的聚类模型效果越好，它们均反映了一个基本理念，那就是我们认为一个好的聚类模型应使簇内样本相距很近，而簇间样本相距很远。</blockquote>

<blockquote>上述这些指标都离不开距离的计算，而距离有多种多样的衡量方式。距离有度量距离和非度量距离之分，所谓非度量指的是不满足距离定义中的第三条性质：A与B的距离同B与C的距离的和大于等于A与C的距离。常用的度量距离有适用于连续或有序离散属性的闵可夫斯基距离、适用于无序离散属性的 VDM（value difference metric）。VDM 认为属性值在各簇分布越一致，属性值的距离越近。</blockquote>

<p class="post-text-noindent">常用的外部指标则有：</p>

<ul>
    <li>Jaccard 系数（Jaccard coefficient, JC）：$$JC = \frac{a}{a+b+c}$$</li>
    <li>FM 指数（Fowlkes and Mallows index, FMI）：$$FMI = \sqrt{\frac{a}\frac{a+b}\dot\frac{a}{a+c}$$</li>
    <li>Rand 指数（Rand index, RI）：$$RI = \frac{2(a+d)}{m(m-1)}$$</li>
    其中 $a$ 代表在聚类模型下同属一类，在参考模型下也同属一类的样本对数量；$d$ 代表在聚类模型下不属于一类，在参考模型下也不属于一类的样本对数量；$b$ 代表在聚类模型下同属一类，但在参考模型下不属于一类的样本对数量；$c$ 代表在聚类模型下不属于一类，但在参考模型下同属一类的样本对数量。
</ul>

<blockquote>所谓参考模型，可以认为是对样本所属类别作了人工标记。</blockquote>

<blockquote>我们通常认为 JC/FMI/Rand 越大的聚类模型效果越好，它们均反映了一个基本理念，那就是我们认为一个好的聚类模型的聚类结果应尽可能与参考模型的聚类结果一致。</blockquote>

<h1>3 结语</h1>

<p>至此，我们对模型选择方法作了相对系统的阐述。读者可能要问：半监督学习和强化学习的模型选择方法是怎样的呢？非常抱歉的是，由于对半监督学习和强化学习了解不多，笔者暂时还没有能力对此做系统性地阐述。甚至这里给出的无监督学习的模型选择方法也显得不够系统。但无论模型选择方法有多么的五彩缤纷，它们的出发点都是一致的，那就是想方设法在当前需求下找到一个最能估计模型实际效果的方法。沿着这样的思路，即使抛开教科书，我们也可以思考并着手构造自己的模型选择方法，没准你的方法还比教科书上好呢。曾短暂指导我进行优化研究的巴西科学院院士袁锦昀老师在讲述如何做研究时曾这样说：有限加有效的知识构成创新的基础。所以，创新不是知道的越多越好，有时候知道的少，反而不容易受到条条框框的束缚。朋友们，勇敢地飞吧，人类知识的边界等待着我们去拓展！</p>

<p>接下来的章节，笔者将依次讨论聚类、树模型（决策树与集成学习）、支持向量机和概率图模型（贝叶斯分类器、隐马尔科夫模型、条件随机场），最后讨论半监督学习和强化学习。对于特征选择和降维内容，笔者将单独拿出来，与缺失值处理和数据标准化等内容一道，共同作为数据预处理专题文章的组成部分。</p>

</div>