# 字节跳动 大数据开发工程师 面试准备

# 1 自我介绍

我叫隆征帆，17年毕业于东北师范大学数学与统计学院统计学专业，17年，18年我两次报考中国人民大学应用统计专业硕士，但非常遗憾都没上，17年复试刷了，18年初试差3分，后来调剂到湘潭大学应用统计专业。17年复试被刷后我曾在人大校内一个科研机构中国调查与数据中心工作了三个月，现在在百度上海研发中心实习。研一下学期，有幸在巴西科学院一位华人院士的指导下做了一学期的科研，方向是数学优化中的子空间方法，但算法最后没有解没有做出来；研二呢我开始把方向重新调回到统计，在研二上学期我做了一个NBA球员投篮数据的分析，文章发表在运筹OR帷幄公众号上，我还为两位同学论文的写作提供了支持，其中有位同学论文发表在现代情报杂志上，在中国知网搜我的名字能找到。研二下学期本来老师联系好了准备去深圳实习，但因为疫情没去成，所以疫情期间我就在家做了个基于中国知网的文献分析系统。我的基本情况大概就是这样。

研一：打杂、自己看一些python基础、计算机基础、numpy logistc 回归优化。做科研（优化中的字空间方法中的字空间共轭梯度法，最后无解）、学习优化（numpy 写无约束优化算法，了解到优化是个很广的领域）

研二：奥运会奖牌数据（urllib）、NBA篮球数据（requests）、微博数据（selenium）、全自动文献分析系统（multiprocessing + aiohttp/grequests）

未来：全自动文献分析系统 毕业论文

# 2 实习经历

## 2.1 百度上海研发中心 爬虫实习生

百度 MEG 舆情平台：百度相关舆情数据的获取、清洗、分析和预警，服务于 MEG 各个产品线

我的工作：

1.异常舆情爬虫的排查与修复

2.数据中心异常爬虫排查与修复文档整理

百度竞媒广告分析平台：竞品线索的挖掘、竞品物料的分析和行业资讯推送，服务于销售部门

我的工作：

1.旗舰店落地页解析（从落地页提取企业名称）

2.客增线索/企名片信息获取自动化（从给定名称检索获得企业详细信息）

3.真机开屏广告抓取（刚接手）

其他工作：

1.内网产品评论数据获取自动化

2.爱企查竟品数据获取自动化（从给定名称检索获得企业详细信息）

3.长江打非数据获取自动化（与某市场监督管理局合作）

4.好奇夜微博评论数据获取

5.虚拟机迁移

6.舆情监控预警

## 2.2 中国人民大学中国调查与数据中心  数据采集部项目助理

CGSS质量控制——数据核查.pdf

# 3 项目经历

HelloPaper + results/data/cnki_report.docx

主要介绍全自动文献分析系统

系统五大模块：爬虫、预处理、分析、图形化界面和日志

作系统的初衷：文献收集整理和分析是科研的第一步，但是实在麻烦

现在对这个系统的打算：当毕业论文，将它扩充到中国知网以外平台、系统完善文献分析功能，把桌面应用转变为 web 应用

未来：世界级文献分析系统

## 3.1 项目中遇到的难点及其处理方法：

**爬虫模块 multiprocessing + aiohttp/grequests + lxml + csv + tkinter**

1.爬取速度和效率的问题

这是我首先面对的一个问题，一开始使用selenium做的，但试了试我就果断放弃了这个选项，因为如果用selenium做的话，会很慢，我数据获取就过不了关。后面用requests库，10000篇文献的基本和详细信息大概40分钟能弄下来，我仍然觉得太慢了，我想将来这个东西大家都能用上，这个速度怎么行啊。于是我就考虑采用aiohttp异步获取，速度上来了不少，还是不满意，后面又加上了multiprocessing。这样10000篇文献的基本和详细信息大概3-4分钟能弄下来。

2.验证码的问题

但是我发现不管换什么检索条件，弄下来的文献每次都不多于750篇，明明与检索条件匹配的文献有上万篇，怎么弄下来只有750篇。于是我就在程序里添加到第16次循环时把html文件存储起来，一看是碰到验证码了。我的第一想法是：我我要用深度学习识别验证码嘛？深度学习还没开始学啊？感觉这个好麻烦？啊要不要不做放弃算了？网上也找不到好的答案，怎么办，要真先学一下深度学习吗，这得花多少时间？老师也催得紧，让我赶快做出来写篇文章。这个问题我想了一天，我在想除了识别验证码就真的就没有其他办法绕过这个反爬吗？知网服务器应该没这么智能吧？要是重新提交一下GET请求获取一下列表，从第16页开始继续获取数据可不可以呢？发现不行，那要不死马当活马医吧，把POST请求也重新提交一下

3.只有6000条结果的问题

解决方法：设计划分时间区间的单独模块，需要进行POST和GET请求获取时间区间的文献量，划分采用递归算法。如果大于6000，二分，二分哪个区间大于6000，就递归划分

4.图形化界面制作问题

复制高级检索功能，方便用户使用，添加了重置检索条件功能，日期自动填充功能。

5.logging不支持多进程的问题

python自带的logging不支持多进程，在多进程下输出混乱

解决方法：自行设计日志模块，实现比较简单，就是同时将信息打印到界面和输出到文件，三个级别 info warning error。

6.系统兼容性的问题

csv模块输出在windows系统下乱码和空行问题

解决方法：添加newline=''参数，encoding采用‘utf-8-sig’

7.信息分散，地址隐蔽的问题

阅读javascript源代码



**预处理模块 panadas+re+time** 

问题不大，主要是繁琐，因为涉及到10个指标的计算



**分析模块 pandas+pyecharts+PIL+numpy+pyhanlp+re+math+python-docx** 

主要问题，分析报告的自动生成，使用python-docx，如何设计分析报告，添加超链接。分析的绘图用的pyecharts，文献推荐的聚类用的pyhanlp



**日志模块**

getpid, datetime, system



整个系统代码中，我清楚地记得有三个地方是借用的别人的代码：第一个是划分日期区间时展平列表；第二个是输出分析报告时裁剪图片；第三个是输出分析报告时添加超链接。

# 4 基础知识

## 4.1 HTTP 请求

http请求由请求行、请求头和请求正文组成

### 4.1.1 请求行

GET https://www.baidu.com HTTP/1.1

### 4.1.2 请求头

Accept：客户端希望接受的数据类型

Accept-Encoding: 客户端可接受的编码

Accept-Language：客户端可接受的语言

Content-Type：互联网媒体类型

Host：请求资源的域名

Cookie：保存在客户端的文本文件，包含客户端或者用户的相关信息

Referer：记录上一次访问的页面地址/此次请求的来源URL

User-Agent: 客户端操作系统及版本、浏览器及版本、浏览器渲染引擎等

### 4.1.3 请求体



## 4.2 HTTP 响应

### 4.2.1 响应状态码

1 代表信息响应

101 协议切换 客户端要求服务器切换协议并且服务器已经切换

2 代表处理成功响应

200 服务器成功处理请求

204 服务器成功处理请求但没有返回任何内容

3 代表重定向响应

301 永久重定向

302 临时重定向

305 请求资源必须通过指定代理才能被访问

4 代表客户端错误

403 服务器接收到请求，但拒绝执行

404 资源不存在

5 代表服务器端错误

500 服务器内部错误

502 代理服务器尝试执行请求时，从上游服务器接收到无效响应

### 4.2.2 响应头

1. Accept-Ranges: bytes
2. Connection: keep-alive
3. Content-Length: 1
4. Content-Type: text/html
5. Date: Sun, 22 Nov 2020 13:07:41 GMT
6. Etag: "58b576df-1"
7. Last-Modified: Tue, 28 Feb 2017 13:10:55 GMT
8. Server: bfe/5

### 4.2.3 响应体



## 4.3 robots协议

robots协议并不是一个要求强制执行的规范

User-Agent:禁止哪些搜索引擎

Allow:允许爬取页面

Disallow:不允许爬取哪些页面

Crawl-delay:限制访问频率

Sitemap:爬取地图

## 4.4 常见反爬虫手段

一、信息校验反爬虫：user-agent, cookies,签名验证、websocket握手验证、websocket消息校验、web socket ping

二、动态渲染反爬虫 ==》动态渲染工具

三、文本混淆反爬虫：图片伪装、CSS偏移、SVG映射、字体反爬虫 ==》光学字符识别

四、特征识别反爬虫

1.识别自动化测试工具

2.限制访问频率

3.css样式隐藏链接（正常用户无法访问，但爬虫工程师可能不会注意到）

五、APP反爬虫

APP代码混淆（对项目中的字符进行映射与压缩）和APP加固

六、验证码反爬虫

验证码：字符验证码、计算型验证码、滑东验证码、文字点选验证码、滑动拼图验证码、图标验证码、空间推理验证码

七、javascript代码混淆

八、信息加密

九、前端禁止事件

## 4.5 Python基础

1.谈一谈你理解的装饰器

装饰器是一种闭包程序结构，用以在函数运行期间动态地增加函数功能。

闭包结构：在函数 A 中定义函数 B，内部函数 B 可以引用外部函数 A 的参数和局部变量，与函数 A 相关的参数和变量都保存在返回的函数 B 中

2.谈一谈你理解的深复制和浅复制的差别

它们的区别体现在复合对象上（包含其他对象的对象，例如列表）。深浅复制都是创建一个新的复合对象，不同的是深复制插入复合对象中对象的拷贝，而浅复制插入复合对象中的原对象。

3.有没有遇到 python3 和 python2 的兼容性问题，有没有工具可以测试多个环境

使用 conda 管理环境

Conda info -e

conda activate env-name

conda deactivate

Conda install -n env-name python=python_version

pip freeze > requirements.txt

pip install -r requirements.txt

4.

## 4.6 数据结构与算法

4.数据结构了解吗，刷过题没

7.两个发散性题目

7.1一个 n 维数组，输出所有 a+b=0 的数字对

for i in a:

​    a+b=0

7.2一个TB的log，里面都是ip地址，内存只有2g，需要得到排名靠前ip地址及其出现次数

  1TB ip

duqufangfa

fuzadu

jiduan

2g

文件分割-读取1.9g-统计结果

# 5 对岗位的理解



# 6 问面试官的问题





